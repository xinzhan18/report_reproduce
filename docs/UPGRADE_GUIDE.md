# Upgrade Guide - Enhanced Features

æœ¬æ–‡æ¡£è¯´æ˜äº†æ–°å¢çš„å·¥ç¨‹åŒ–æ”¹è¿›åŠŸèƒ½ã€‚

## ğŸ¯ æ–°å¢åŠŸèƒ½æ¦‚è§ˆ

### 1. **å¤šAPI Keyæ”¯æŒ**
æ¯ä¸ªagentå¯ä»¥ä½¿ç”¨ä¸åŒçš„API keyå’ŒLLMæ¨¡å‹ã€‚

### 2. **å¢å¼ºæ•°æ®æŒä¹…åŒ–**
- å®Œæ•´çš„æ•°æ®åº“schemaï¼ˆSQLiteï¼‰
- æ–‡æ¡£é˜…è¯»å†å²è¿½è¸ª
- å¼•ç”¨è‡ªåŠ¨ç®¡ç†

### 3. **PDFé˜…è¯»æ”¯æŒ**
- è‡ªåŠ¨ä¸‹è½½arXiv PDF
- æ–‡æœ¬æå–å’Œåˆ†æ
- å†…å®¹æœç´¢

### 4. **è¿­ä»£è®°å¿†ç³»ç»Ÿ**
- è®°å½•æ¯è½®å‘ç°ã€é—®é¢˜ã€æ”¹è¿›
- è·¨é¡¹ç›®å­¦ä¹ 
- æ™ºèƒ½è¿­ä»£å†³ç­–

### 5. **å¼•ç”¨ç®¡ç†ç³»ç»Ÿ**
- è‡ªåŠ¨ç”Ÿæˆå¼•ç”¨
- å¤šç§å¼•ç”¨æ ¼å¼ï¼ˆAPA, IEEE, Chicagoï¼‰
- BibTeXå¯¼å‡º

## ğŸ“š æ•°æ®åº“Schema

æ–°å¢æ•°æ®åº“è¡¨ï¼š

```sql
- papers              # æ‰€æœ‰æŸ¥çœ‹è¿‡çš„è®ºæ–‡
- citations           # å¼•ç”¨è®°å½•
- projects            # ç ”ç©¶é¡¹ç›®
- iterations          # è¿­ä»£å†å²
- memories            # è·¨é¡¹ç›®è®°å¿†
- agent_executions    # Agentæ‰§è¡Œæ—¥å¿—
- document_access_log # æ–‡æ¡£è®¿é—®æ—¥å¿—
```

## ğŸ”‘ é…ç½®å¤šAPI Key

### æ–¹æ³•1ï¼šç¯å¢ƒå˜é‡

```bash
# æ¯ä¸ªagentç‹¬ç«‹é…ç½®
IDEATION_API_KEY=sk-ant-xxx
PLANNING_API_KEY=sk-ant-yyy
EXPERIMENT_API_KEY=sk-ant-zzz
WRITING_API_KEY=sk-ant-www
```

### æ–¹æ³•2ï¼šJSONé…ç½®æ–‡ä»¶

åˆ›å»º `config/llm_keys.json`:

```json
{
  "ideation": {
    "provider": "anthropic",
    "api_key": "your_key",
    "model_id": "claude-sonnet-4-5-20250929",
    "temperature": 0.7
  },
  "experiment": {
    "provider": "openai",
    "api_key": "your_openai_key",
    "model_id": "gpt-4-turbo-preview",
    "temperature": 0.2
  }
}
```

## ğŸ“– ä½¿ç”¨PDFé˜…è¯»åŠŸèƒ½

```python
from tools.pdf_reader import PDFReader

# åˆå§‹åŒ–PDFé˜…è¯»å™¨
pdf_reader = PDFReader()

# ä¸‹è½½å¹¶åˆ†æPDF
arxiv_id = "2301.12345"
summary = pdf_reader.get_paper_summary(arxiv_id)

print(f"Has PDF: {summary['has_pdf']}")
print(f"Sections: {summary['sections'].keys()}")

# æœç´¢PDFå†…å®¹
results = pdf_reader.search_pdf_content(
    arxiv_id,
    search_terms=["momentum", "sharpe ratio"]
)
```

## ğŸ“ ä½¿ç”¨å¼•ç”¨ç®¡ç†

```python
from tools.citation_manager import CitationManager

# åˆ›å»ºå¼•ç”¨ç®¡ç†å™¨
citations = CitationManager(
    project_id="my_project",
    citation_style="APA"  # æˆ– IEEE, Chicago, Harvard
)

# æ·»åŠ å¼•ç”¨
cite_key = citations.cite_paper(
    arxiv_id="2301.12345",
    context="This approach was inspired by..."
)

# ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
bibliography = citations.generate_bibliography()

# å¯¼å‡ºBibTeX
bibtex = citations.export_bibtex()
```

## ğŸ”„ ä½¿ç”¨è¿­ä»£è®°å¿†

```python
from core.iteration_memory import IterationMemory, IterationAnalyzer

# åˆå§‹åŒ–è¿­ä»£è®°å¿†
memory = IterationMemory(project_id="my_project")

# å¼€å§‹æ–°è¿­ä»£
iteration_id = memory.start_iteration(
    iteration_number=1,
    agent_name="experiment"
)

# è®°å½•å‘ç°
memory.record_finding(
    "Strategy performs well in trending markets",
    importance=0.9,
    tags=["momentum", "trend"]
)

# è®°å½•é—®é¢˜
memory.record_issue(
    "High drawdown during market reversals",
    severity="high",
    tags=["risk", "drawdown"]
)

# è®°å½•æ”¹è¿›å»ºè®®
memory.record_improvement(
    "Add volatility filter to reduce whipsaws",
    category="methodology",
    tags=["filter", "risk_management"]
)

# å®Œæˆè¿­ä»£
memory.complete_iteration(
    iteration_id=iteration_id,
    status="success",
    findings=["Finding 1", "Finding 2"],
    issues=["Issue 1"],
    improvements=["Improvement 1"],
    metrics={"sharpe_ratio": 1.2}
)

# è·å–å†å²
previous_findings = memory.get_previous_findings()
summary = memory.get_iteration_summary()

# å†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£
should_continue, reason = memory.should_continue_iterating()
```

## ğŸ’¾ æ•°æ®åº“æŸ¥è¯¢ç¤ºä¾‹

```python
from core.database import get_database

db = get_database()

# æŸ¥çœ‹æ‰€æœ‰é¡¹ç›®
projects = db.conn.execute("SELECT * FROM projects").fetchall()

# æŸ¥çœ‹æŸä¸ªé¡¹ç›®çš„æ‰€æœ‰å¼•ç”¨
citations = db.get_citations("project_id_here")

# æŸ¥çœ‹è¿­ä»£å†å²
iterations = db.get_iteration_history("project_id_here")

# æŸ¥çœ‹è®°å¿†/å­¦ä¹ 
memories = db.get_relevant_memories(memory_type="improvement", limit=10)

# æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è¯»
has_read = db.has_paper_been_read("2301.12345", "project_id")
```

## ğŸ¨ æ–°çš„å·¥ä½œæµç¨‹

### å®Œæ•´å·¥ä½œæµwithæ–°åŠŸèƒ½:

```python
from core.pipeline import run_research_pipeline
from core.database import get_database
from tools.citation_manager import CitationManager
from tools.pdf_reader import PDFReader
from core.iteration_memory import IterationMemory

# 1. è¿è¡Œç ”ç©¶æµç¨‹
result = run_research_pipeline("momentum strategies")

project_id = result["project_id"]

# 2. æ£€æŸ¥å¼•ç”¨
db = get_database()
citations = db.get_citations(project_id)
print(f"Total citations: {len(citations)}")

# 3. ç”Ÿæˆå®Œæ•´å‚è€ƒæ–‡çŒ®
citation_mgr = CitationManager(project_id, citation_style="APA")
bibliography = citation_mgr.generate_bibliography()

# 4. æŸ¥çœ‹è¿­ä»£å†å²
memory = IterationMemory(project_id)
summary = memory.get_iteration_summary()
print(summary)

# 5. ä¸‹è½½æ‰€æœ‰å¼•ç”¨çš„PDF
pdf_reader = PDFReader()
for citation in citations:
    arxiv_id = citation["arxiv_id"]
    pdf_reader.download_pdf(arxiv_id)
```

## ğŸ“Š ç›‘æ§å’Œç»Ÿè®¡

```python
from config.multi_llm_config import get_llm_manager
from core.database import get_database

# LLMé…ç½®ç»Ÿè®¡
llm_mgr = get_llm_manager()
stats = llm_mgr.get_statistics()
print(f"Configured agents: {stats['agents']}")
print(f"Providers: {stats['providers']}")

# æ•°æ®åº“ç»Ÿè®¡
db = get_database()

# æ€»è®ºæ–‡æ•°
total_papers = db.conn.execute("SELECT COUNT(*) FROM papers").fetchone()[0]

# æ€»å¼•ç”¨æ•°
total_citations = db.conn.execute("SELECT COUNT(*) FROM citations").fetchone()[0]

# æ€»è®°å¿†æ•°
total_memories = db.conn.execute("SELECT COUNT(*) FROM memories").fetchone()[0]

print(f"Papers in database: {total_papers}")
print(f"Total citations: {total_citations}")
print(f"Memories stored: {total_memories}")
```

## ğŸ”§ ä¾èµ–æ›´æ–°

æ–°å¢ä¾èµ–é¡¹éœ€è¦å®‰è£…ï¼š

```bash
pip install PyPDF2  # PDFè¯»å–
```

åœ¨ `requirements.txt` ä¸­å·²åŒ…å«ã€‚

## ğŸš€ è¿ç§»ç°æœ‰é¡¹ç›®

å¦‚æœæ‚¨æœ‰ä½¿ç”¨æ—§ç‰ˆæœ¬åˆ›å»ºçš„é¡¹ç›®ï¼š

1. **å¤‡ä»½æ•°æ®**ï¼š
```bash
cp -r outputs outputs_backup
```

2. **è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–**ï¼š
```python
from core.database import get_database
db = get_database()  # è‡ªåŠ¨åˆ›å»ºæ‰€æœ‰è¡¨
```

3. **å¯é€‰ï¼šå¯¼å…¥æ—§é¡¹ç›®æ•°æ®**ï¼š
```python
# æ‰‹åŠ¨å¯¼å…¥æ—§é¡¹ç›®çš„è®ºæ–‡å’Œå¼•ç”¨åˆ°æ–°æ•°æ®åº“
```

## âš™ï¸ é…ç½®é€‰é¡¹

### .env æ–°å¢é€‰é¡¹:

```bash
# å¼•ç”¨æ ¼å¼
CITATION_STYLE=APA

# PDFç¼“å­˜
PDF_CACHE_ENABLED=true
PDF_AUTO_DOWNLOAD=true

# è¿­ä»£è®¾ç½®
MAX_ITERATIONS=5
IMPROVEMENT_THRESHOLD=0.05

# è®°å¿†ä¿ç•™æœŸ
MEMORY_RETENTION_DAYS=365
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. API Keyç®¡ç†
- ä¸ºä¸åŒagentä½¿ç”¨ä¸åŒkeyä»¥åˆ†æ•£è´Ÿè½½
- ä½¿ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹ï¼ˆHaikuï¼‰å¤„ç†ç®€å•ä»»åŠ¡
- ç›‘æ§å„agentçš„APIä½¿ç”¨é‡

### 2. PDFç¼“å­˜
- å®šæœŸæ¸…ç†æ—§PDFï¼ˆ`pdf_reader.clean_cache(older_than_days=90)`ï¼‰
- å¤§é¡¹ç›®è€ƒè™‘å¤–éƒ¨å­˜å‚¨

### 3. è¿­ä»£ç®¡ç†
- è®¾ç½®åˆç†çš„ `MAX_ITERATIONS`
- æ¯æ¬¡è¿­ä»£è®°å½•è¯¦ç»†çš„findingså’Œimprovements
- ä½¿ç”¨ `should_continue_iterating()` è‡ªåŠ¨å†³ç­–

### 4. å¼•ç”¨ç®¡ç†
- åŠæ—¶è®°å½•å¼•ç”¨ï¼ˆåœ¨é˜…è¯»è®ºæ–‡æ—¶ï¼‰
- å®šæœŸéªŒè¯å¼•ç”¨ï¼ˆ`citations.validate_citations()`ï¼‰
- å¯¼å‡ºBibTeXå¤‡ä»½

## ğŸ“– æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•è·å–æ›´å¤šä½¿ç”¨ç¤ºä¾‹ï¼š
- `examples/multi_api_keys.py` - å¤šAPI keyé…ç½®
- `examples/pdf_analysis.py` - PDFåˆ†æå·¥ä½œæµ
- `examples/iteration_learning.py` - è¿­ä»£å­¦ä¹ ç¤ºä¾‹
- `examples/citation_workflow.py` - å¼•ç”¨ç®¡ç†å·¥ä½œæµ

## â“ å¸¸è§é—®é¢˜

**Q: æ˜¯å¦å¿…é¡»ä¸ºæ¯ä¸ªagenté…ç½®ç‹¬ç«‹API keyï¼Ÿ**
A: ä¸æ˜¯å¿…é¡»çš„ã€‚å¦‚æœåªè®¾ç½® `ANTHROPIC_API_KEY`ï¼Œæ‰€æœ‰agentä¼šå…±äº«ã€‚ç‹¬ç«‹é…ç½®æ˜¯å¯é€‰çš„ä¼˜åŒ–ã€‚

**Q: PDFä¸‹è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
A: ç³»ç»Ÿä¼šç»§ç»­ä½¿ç”¨è®ºæ–‡çš„abstractã€‚å¯ä»¥ç¨åæ‰‹åŠ¨ä¸‹è½½æˆ–ç¦ç”¨ `PDF_AUTO_DOWNLOAD`ã€‚

**Q: æ•°æ®åº“ä¼šå˜å¾—å¾ˆå¤§å—ï¼Ÿ**
A: ä¸»è¦å­˜å‚¨å…ƒæ•°æ®ã€‚å®šæœŸæ¸…ç†æ—§é¡¹ç›®å’ŒPDFç¼“å­˜å¯æ§åˆ¶å¤§å°ã€‚

**Q: å¦‚ä½•å¯¼å‡ºæ‰€æœ‰æ•°æ®ï¼Ÿ**
A: æ•°æ®åº“æ˜¯æ ‡å‡†SQLiteï¼Œå¯ä»¥ç”¨ä»»ä½•SQLiteå·¥å…·å¯¼å‡ºã€‚å¼•ç”¨å¯å¯¼å‡ºä¸ºBibTeXã€‚

---

**å‡çº§å®Œæˆï¼** ç°åœ¨æ‚¨çš„ç³»ç»Ÿå…·æœ‰å®Œæ•´çš„å·¥ç¨‹åŒ–èƒ½åŠ›ã€‚
